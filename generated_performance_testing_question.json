{
  "question": "What's the difference between latency, throughput, and percentiles in performance testing?",
  "answer": "Latency = response time per request, Throughput = requests per second, Percentiles = distribution of response times (p50, p95, p99)",
  "explanation": "## Why Asked\nTests understanding of fundamental performance metrics essential for system design and optimization.\n## Key Concepts\n- Latency: Time for single request completion\n- Throughput: System capacity over time period\n- Percentiles: Statistical distribution of response times\n- p50 (median), p95, p99 for SLA monitoring\n## Code Example\n```\n// Benchmark example\nconst results = await benchmark(() => {
  return apiCall();
}, { iterations: 1000 });

console.log(`Latency: ${results.latency}ms`);
console.log(`Throughput: ${results.throughput} req/s`);
console.log(`p95: ${results.percentiles.p95}ms`);
```\n## Follow-up Questions\n- How do you optimize for low latency vs high throughput?\n- What's a good p99 target for web APIs?\n- How do percentiles help identify performance issues?",
  "diagram": "flowchart TD\n  A[Request] --> B[Process Request]\n  B --> C[Measure Latency]\n  C --> D[Return Response]\n  D --> E[Track Throughput]\n  E --> F[Calculate Percentiles]\n  F --> G[Monitor SLAs]",
  "companies": ["Google", "Amazon", "Meta"],
  "sourceUrl": null,
  "videos": {"shortVideo": null, "longVideo": null}
}