[
  {
    "id": "sd-1",
    "question": "Can you explain the Load Balancer strategy? When would you use Layer 4 vs Layer 7 load balancing?",
    "answer": "Load Balancing distributes traffic across multiple servers to ensure reliability and scalability.",
    "explanation": "A Load Balancer (LB) acts as a reverse proxy. \n\n**Layer 4 (Transport Layer)**: Distributes based on IP/Port. Fast, low overhead, but no context of content. Good for simple packet distribution.\n\n**Layer 7 (Application Layer)**: Inspects HTTP headers/content. Can route based on URL/cookies (e.g., /api to Service A, /static to Service B). More expensive but smarter.\n\n**Common Algorithms**:\n- **Round Robin**: Sequential.\n- **Least Connections**: Sends to server with fewest active connections.\n- **IP Hash**: Ensures a user always goes to the same server (sticky sessions).",
    "tags": [
      "infra",
      "scale",
      "networking"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "graph LR\n    User --> LB[Load Balancer]\n    LB -->|Layer 4| S1[\"Server 1<br/>IP:Port\"]\n    LB -->|Layer 7| S2[\"Server 2<br/>/api\"]\n    style LB fill:#fff,stroke:#000,color:#000"
  },
  {
    "id": "sd-2",
    "question": "What is Consistent Hashing and why is it critical for distributed caches?",
    "answer": "Consistent Hashing maps keys to a ring of nodes to minimize data movement when scaling.",
    "explanation": "In standard `hash(key) % N`, adding a node changes `N`, causing nearly ALL keys to remap (cache stampede).\n\n**Consistent Hashing** maps both servers and keys to a circle (0-360Â°). Keys map to the next server clockwise.\n\n**Benefit**: Adding/removing a node only affects the immediate neighbors (k/N keys move), not the whole cluster.\n\nUsed in: DynamoDB, Cassandra, Discord Ringpop.",
    "tags": [
      "hashing",
      "dist-sys",
      "caching"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "\ngraph TD\n    subgraph Hash Ring\n    N1((Node 1)) --- N2((Node 2))\n    N2 --- N3((Node 3))\n    N3 --- N1\n    end\n    Key[Key K] -.->|Clockwise| N2\n    style N2 fill:#f00,stroke:#fff,color:#fff\n"
  },
  {
    "id": "sd-3",
    "question": "Explain the CAP Theorem. Can you really 'choose two'?",
    "answer": "CAP states a distributed store can only provide 2 of 3: Consistency, Availability, Partition Tolerance.",
    "explanation": "**Partition Tolerance (P)** is NOT optional in distributed systems (networks fail). \n\nSo the real choice is **CP vs AP** during a partition:\n\n- **CP (Consistency)**: Return error/timeout if data can't be synced. (e.g., Banking - better to fail than show wrong balance).\n- **AP (Availability)**: Return stale data but keep running. (e.g., Facebook Feed - better to show old posts than nothing).\n\n**PACELC Theorem** extends this: Else (when no partition), choose Latency (L) vs Consistency (C).",
    "tags": [
      "theory",
      "dist-sys",
      "database"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "graph TD\n    CAP[CAP Theorem]\n    CAP --> C[Consistency]\n    CAP --> A[Availability]\n    CAP --> P[Partition Tolerance]\n    Note[Pick 2 of 3]\n    style Note fill:#f59e0b,stroke:#fff,color:#000"
  },
  {
    "id": "sd-4",
    "question": "How do you handle Database Sharding? What are the downsides?",
    "answer": "Sharding splits a large database into smaller, faster, easily managed parts called data shards.",
    "explanation": "**Horizontal Partitioning**: Splitting rows based on a Shard Key (e.g., UserID).\n\n**Downsides/Challenges**:\n1. **Resharding**: Hard to move data when a shard fills up.\n2. **Hotspot Key**: If Justin Bieber is on Shard 1, Shard 1 melts down.\n3. **Joins**: Cross-shard joins are expensive/impossible.\n\n**Mitigation**: Consistent Hashing, Virtual Nodes.",
    "tags": [
      "db",
      "scale",
      "architecture"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "database",
    "diagram": "\ngraph TD\n    App --> Router\n    Router -->|ID < 100| S1[(Shard 1)]\n    Router -->|ID > 100| S2[(Shard 2)]\n"
  },
  {
    "id": "sd-5",
    "question": "Design a Rate Limiter. What algorithms would you consider?",
    "answer": "Rate Limiting controls the amount of traffic sent or received by a network interface controller.",
    "explanation": "Prevents DoS attacks and resource starvation.\n\n**Algorithms**:\n1. **Token Bucket**: Tokens added at rate `r`. Request consumes token. Allows bursts.\n2. **Leaky Bucket**: Requests enter queue, processed at constant rate. Smooths traffic.\n3. **Fixed Window**: Count requests in 1s window. Edge case: 2x traffic at window boundary.\n4. **Sliding Window Log**: Precise but expensive (stores timestamps).\n\n**Implementation**: Redis (Lua scripts for atomicity).",
    "tags": [
      "security",
      "api",
      "algorithms"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "\ngraph LR\n    Req[Request] --> Check{Buckets Full?}\n    Check -->|No| Process[Process]\n    Check -->|Yes| Drop[429 Too Many Requests]\n"
  },
  {
    "id": "gh-31",
    "question": "What is Scalability in DevOps?",
    "answer": "Scalability is the capability of a system to handle a growing amount of work by adding resources to the system. There are two types of scaling:",
    "explanation": "Scalability is the capability of a system to handle a growing amount of work by adding resources to the system. There are two types of scaling:\n\n1. **Vertical Scaling (Scale Up):**\n- Adding more power to existing resources\n- Example: Upgrading CPU/RAM\n\n2. **Horizontal Scaling (Scale Out):**\n- Adding more resources\n- Example: Adding more servers",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph TD\n    subgraph Vertical\n    S1[Small] --> S2[Large]\n    end\n    subgraph Horizontal\n    H1[Server] --- H2[Server] --- H3[Server]\n    end\n"
  },
  {
    "id": "gh-32",
    "question": "What is High Availability?",
    "answer": "High Availability (HA) is a characteristic of a system that aims to ensure an agreed level of operational performance, usually uptime, for a higher th...",
    "explanation": "High Availability (HA) is a characteristic of a system that aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period.\n\nKey components:\n1. **Redundancy:**\n- Multiple instances\n- No single point of failure\n\n2. **Monitoring:**\n- Health checks\n- Automated failover\n\n3. **Load Balancing:**\n- Traffic distribution\n- Resource optimization",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph TD\n    LB[Load Balancer] --> S1[Server 1]\n    LB --> S2[Server 2]\n    S1 -.->|Failover| S2\n"
  },
  {
    "id": "gh-33",
    "question": "What is Load Balancing?",
    "answer": "Load Balancing is the process of distributing network traffic across multiple servers to ensure no single server bears too much demand.",
    "explanation": "Load Balancing is the process of distributing network traffic across multiple servers to ensure no single server bears too much demand.\n\nCommon Load Balancing algorithms:\n1. **Round Robin**\n2. **Least Connections**\n3. **IP Hash**\n4. **Weighted Round Robin**\n5. **Resource-Based**\n\nExample of Nginx Load Balancer configuration:\n```nginx\nhttp {\nupstream backend {\nserver backend1.example.com;\nserver backend2.example.com;\nserver backend3.example.com;\n}\n\nserver {\nlisten 80;\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n```",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure"
  },
  {
    "id": "gh-34",
    "question": "What is Auto Scaling?",
    "answer": "Auto Scaling is a feature that automatically adjusts the number of compute resources based on the current demand.",
    "explanation": "Auto Scaling is a feature that automatically adjusts the number of compute resources based on the current demand.\n\nKey concepts:\n1. **Scaling Policies:**\n- Target tracking\n- Step scaling\n- Simple scaling\n\n2. **Metrics:**\n- CPU utilization\n- Memory usage\n- Request count\n- Custom metrics\n\nExample of AWS Auto Scaling configuration:\n```yaml\nAutoScalingGroup:\nMinSize: 1\nMaxSize: 10\nDesiredCapacity: 2\nHealthCheckType: ELB\nHealthCheckGracePeriod: 300\nLaunchTemplate:\nLaunchTemplateId: !Ref LaunchTemplate\nVersion: !GetAtt LaunchTemplate.LatestVersionNumber\n```",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph LR\n    Metrics[Metrics] --> ASG[Auto Scaling]\n    ASG -->|Scale Out| Add[Add Instances]\n    ASG -->|Scale In| Remove[Remove Instances]\n"
  }
]